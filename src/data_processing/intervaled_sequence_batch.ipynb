{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Sequencing & Batch creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 16:51:04.992213: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 16:51:05.410048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:51:05.410090: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-15 16:51:07.358234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:51:07.358341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:51:07.358349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>trans_timedelta</th>\n",
       "      <th>trans_month_sin</th>\n",
       "      <th>trans_month_cos</th>\n",
       "      <th>trans_week_sin</th>\n",
       "      <th>trans_week_cos</th>\n",
       "      <th>trans_hour_sin</th>\n",
       "      <th>trans_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>585</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.408741</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.282429</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.634966</td>\n",
       "      <td>-2.500818</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>1.250178</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.197699</td>\n",
       "      <td>1.433818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>0.233378</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.293527</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>57.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.634966</td>\n",
       "      <td>-2.500818</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>1.250178</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.197699</td>\n",
       "      <td>1.433818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860</td>\n",
       "      <td>366</td>\n",
       "      <td>7</td>\n",
       "      <td>0.942184</td>\n",
       "      <td>-1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.280243</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>-0.634966</td>\n",
       "      <td>-2.500818</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>1.250178</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.197699</td>\n",
       "      <td>1.433818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157381</td>\n",
       "      <td>-1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.287590</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.634966</td>\n",
       "      <td>-2.500818</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>1.250178</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.197699</td>\n",
       "      <td>1.433818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195</td>\n",
       "      <td>521</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.176470</td>\n",
       "      <td>-1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-0.293693</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>58.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.634966</td>\n",
       "      <td>-2.500818</td>\n",
       "      <td>1.529069</td>\n",
       "      <td>1.250178</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.197699</td>\n",
       "      <td>1.433818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cc_num  merchant  category       amt  gender   lat  long  city_pop  \\\n",
       "0     146       585        12 -0.408741       1  29.0  93.0 -0.282429   \n",
       "1      51       105         2  0.233378       1  62.0  50.0 -0.293527   \n",
       "2     860       366         7  0.942184      -1  69.0  95.0 -0.280243   \n",
       "3     696        39         1 -0.157381      -1  37.0  66.0 -0.287590   \n",
       "4     195       521        11 -0.176470      -1  62.0  79.0 -0.293693   \n",
       "\n",
       "    unix_time  merch_lat  merch_long  is_fraud  age  trans_timedelta  \\\n",
       "0  1325376018       49.0        25.0         0   30        -0.634966   \n",
       "1  1325376044       57.0        79.0         0   40        -0.634966   \n",
       "2  1325376051       63.0        73.0         0   56        -0.634966   \n",
       "3  1325376076        7.0        72.0         0   51        -0.634966   \n",
       "4  1325376186       58.0        93.0         0   32        -0.634966   \n",
       "\n",
       "   trans_month_sin  trans_month_cos  trans_week_sin  trans_week_cos  \\\n",
       "0        -2.500818         1.529069        1.250178        0.671264   \n",
       "1        -2.500818         1.529069        1.250178        0.671264   \n",
       "2        -2.500818         1.529069        1.250178        0.671264   \n",
       "3        -2.500818         1.529069        1.250178        0.671264   \n",
       "4        -2.500818         1.529069        1.250178        0.671264   \n",
       "\n",
       "   trans_hour_sin  trans_hour_cos  \n",
       "0        0.197699        1.433818  \n",
       "1        0.197699        1.433818  \n",
       "2        0.197699        1.433818  \n",
       "3        0.197699        1.433818  \n",
       "4        0.197699        1.433818  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from typing import Optional\n",
    "\n",
    "df = pd.read_csv('../../datasets/modified/modified_sparkov_full.csv', index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is mportant things to note that the dataset is **sorted by credit card number and then by chronological order**\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating intervaled sequences of transactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create sequences, we need:\n",
    "1. Create a new Dataframe to host the new dataset format\n",
    "2. Iterate through the original dataset\n",
    "3. With a cutoff length of **100**, each row of the new dataset will contain 100 transaction, in chronological order, of a given card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dividing into train, validation and test datasets\n",
    "training, validation and test datasets are splt based on the time period they are placed in, to simulate real life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size = 0.8\n",
    "valid_size=0.1\n",
    "len_cc = 1000\n",
    "cutoff_length = 6\n",
    "\n",
    "train_index = int(len(df)*train_size)\n",
    "\n",
    "df_train = df[0:train_index]\n",
    "df_rem = df[train_index:]\n",
    "\n",
    "valid_index = int(len(df)*valid_size)\n",
    "\n",
    "df_valid = df[train_index:train_index+valid_index]\n",
    "df_test = df[train_index+valid_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "df_list = [df_train, df_valid, df_test]\n",
    "fraud_seq_list = [{}, {}, {}]\n",
    "non_fraud_seq_list = [{}, {}, {}]\n",
    "\n",
    "for set_id in range(len(df_list)):\n",
    "    set = df_list[set_id].groupby(['cc_num'])\n",
    "    for name, group in set:\n",
    "        fraud_seq_list[set_id][name] = [] # to initialize empty list of sequences\n",
    "        non_fraud_seq_list[set_id][name] = [] \n",
    "        \n",
    "        sequence_list = group.rolling(window=cutoff_length)#\n",
    "        for sequence in dropwhile(lambda w: len(w) < cutoff_length, group.rolling(window=cutoff_length)):\n",
    "            sequence = sequence.reset_index(drop=True)\n",
    "            if (sequence.tail(1)[\"is_fraud\"] == 1).bool():\n",
    "                fraud_seq_list[set_id][name] += [sequence.to_numpy()]\n",
    "            else:\n",
    "                non_fraud_seq_list[set_id][name] += [sequence.to_numpy()]\n",
    "\n",
    "\n",
    "fraud_seq_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset needs to be ordered in such a way that the automatic creation of batches in Tensorflow results exactly in the way we want. For that is it is necessary to:\n",
    "- A sequence needs to have \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "\n",
    "tf.convert_to_tensor(non_fraud_seq_list[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1c8d70582e99c6d94fd9ce1c8520e52ffd743356a35b6af43fc12b76ecf0483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
