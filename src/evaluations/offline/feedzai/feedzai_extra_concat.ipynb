{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from machine_learning.models import FeedzaiExtraConcatProduction\n",
    "from data_processing.batch_generator import load_test_set\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedzaiExtraConcatProduction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transaction = np.load(f'{path}data/test/all_transactions.npy')[0]\n",
    "test_labels = np.load(f'{path}data/test/all_labels.npy').astype(float)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.load(f'{path}data/test/all_transactions.npy'), \n",
    "     test_labels)\n",
    ").batch(1)\n",
    "# initialize weights\n",
    "model(np.expand_dims(sample_transaction, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063233</td>\n",
       "      <td>0.993409</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1012224.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4723.0</td>\n",
       "      <td>0.080682</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.635925</td>\n",
       "      <td>0.049526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>514.0</td>\n",
       "      <td>1013450.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>0.400936</td>\n",
       "      <td>0.104941</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>0.166343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.994952</td>\n",
       "      <td>618.0</td>\n",
       "      <td>1013354.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>0.417004</td>\n",
       "      <td>0.126174</td>\n",
       "      <td>0.807021</td>\n",
       "      <td>0.193730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>0.994867</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1013242.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.197330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>0.995057</td>\n",
       "      <td>782.0</td>\n",
       "      <td>1013297.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>0.459190</td>\n",
       "      <td>0.159657</td>\n",
       "      <td>0.827863</td>\n",
       "      <td>0.236934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.994884</td>\n",
       "      <td>659.0</td>\n",
       "      <td>1013243.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>0.403305</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>0.801210</td>\n",
       "      <td>0.201776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.995128</td>\n",
       "      <td>826.0</td>\n",
       "      <td>1013325.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>4072.0</td>\n",
       "      <td>0.480512</td>\n",
       "      <td>0.168640</td>\n",
       "      <td>0.830953</td>\n",
       "      <td>0.249660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.995033</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1013334.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>4178.0</td>\n",
       "      <td>0.448878</td>\n",
       "      <td>0.146999</td>\n",
       "      <td>0.818110</td>\n",
       "      <td>0.221470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>0.995077</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1013329.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>0.464135</td>\n",
       "      <td>0.157207</td>\n",
       "      <td>0.833556</td>\n",
       "      <td>0.234864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1013253.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>4228.0</td>\n",
       "      <td>0.409786</td>\n",
       "      <td>0.136791</td>\n",
       "      <td>0.810073</td>\n",
       "      <td>0.205113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>0.995191</td>\n",
       "      <td>858.0</td>\n",
       "      <td>1013357.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>0.499127</td>\n",
       "      <td>0.175174</td>\n",
       "      <td>0.835527</td>\n",
       "      <td>0.259332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1013356.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>0.461923</td>\n",
       "      <td>0.151082</td>\n",
       "      <td>0.834179</td>\n",
       "      <td>0.227692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.994916</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1013261.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>4224.0</td>\n",
       "      <td>0.413243</td>\n",
       "      <td>0.137607</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.206463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.020863</td>\n",
       "      <td>0.995232</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1013381.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>4022.0</td>\n",
       "      <td>0.511384</td>\n",
       "      <td>0.178849</td>\n",
       "      <td>0.843702</td>\n",
       "      <td>0.265013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.995184</td>\n",
       "      <td>752.0</td>\n",
       "      <td>1013456.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>0.496697</td>\n",
       "      <td>0.153532</td>\n",
       "      <td>0.840899</td>\n",
       "      <td>0.234560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.021995</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1013441.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>4169.0</td>\n",
       "      <td>0.484064</td>\n",
       "      <td>0.148836</td>\n",
       "      <td>0.832006</td>\n",
       "      <td>0.227670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.021327</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>766.0</td>\n",
       "      <td>1013457.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>4132.0</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>0.156390</td>\n",
       "      <td>0.839108</td>\n",
       "      <td>0.238444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>0.994930</td>\n",
       "      <td>694.0</td>\n",
       "      <td>1013255.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>0.418829</td>\n",
       "      <td>0.141690</td>\n",
       "      <td>0.813645</td>\n",
       "      <td>0.211747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1013407.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>4025.0</td>\n",
       "      <td>0.518409</td>\n",
       "      <td>0.178236</td>\n",
       "      <td>0.844814</td>\n",
       "      <td>0.265269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>763.0</td>\n",
       "      <td>1013460.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>0.501644</td>\n",
       "      <td>0.155778</td>\n",
       "      <td>0.844305</td>\n",
       "      <td>0.237732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy     TP         TN      FP      FN   \n",
       "0       0  0.063233         0.993409  175.0  1012224.0  1994.0  4723.0  \\\n",
       "1       1  0.024547         0.994945  514.0  1013450.0   768.0  4384.0   \n",
       "2       2  0.024475         0.994952  618.0  1013354.0   864.0  4280.0   \n",
       "3       3  0.026863         0.994867  643.0  1013242.0   976.0  4255.0   \n",
       "4       4  0.022445         0.995057  782.0  1013297.0   921.0  4116.0   \n",
       "5       5  0.026015         0.994884  659.0  1013243.0   975.0  4239.0   \n",
       "6       6  0.022192         0.995128  826.0  1013325.0   893.0  4072.0   \n",
       "7       7  0.023710         0.995033  720.0  1013334.0   884.0  4178.0   \n",
       "8       8  0.022107         0.995077  770.0  1013329.0   889.0  4128.0   \n",
       "9       9  0.024750         0.994904  670.0  1013253.0   965.0  4228.0   \n",
       "10     10  0.021681         0.995191  858.0  1013357.0   861.0  4040.0   \n",
       "11     11  0.022212         0.995074  740.0  1013356.0   862.0  4158.0   \n",
       "12     12  0.029017         0.994916  674.0  1013261.0   957.0  4224.0   \n",
       "13     13  0.020863         0.995232  876.0  1013381.0   837.0  4022.0   \n",
       "14     14  0.021198         0.995184  752.0  1013456.0   762.0  4146.0   \n",
       "15     15  0.021995         0.995147  729.0  1013441.0   777.0  4169.0   \n",
       "16     16  0.021327         0.995199  766.0  1013457.0   761.0  4132.0   \n",
       "17     17  0.024489         0.994930  694.0  1013255.0   963.0  4204.0   \n",
       "18     18  0.020551         0.995255  873.0  1013407.0   811.0  4025.0   \n",
       "19     19  0.020955         0.995199  763.0  1013460.0   758.0  4135.0   \n",
       "\n",
       "    precision    recall       auc  f1_score  \n",
       "0    0.080682  0.035729  0.635925  0.049526  \n",
       "1    0.400936  0.104941  0.808719  0.166343  \n",
       "2    0.417004  0.126174  0.807021  0.193730  \n",
       "3    0.397159  0.131278  0.796970  0.197330  \n",
       "4    0.459190  0.159657  0.827863  0.236934  \n",
       "5    0.403305  0.134545  0.801210  0.201776  \n",
       "6    0.480512  0.168640  0.830953  0.249660  \n",
       "7    0.448878  0.146999  0.818110  0.221470  \n",
       "8    0.464135  0.157207  0.833556  0.234864  \n",
       "9    0.409786  0.136791  0.810073  0.205113  \n",
       "10   0.499127  0.175174  0.835527  0.259332  \n",
       "11   0.461923  0.151082  0.834179  0.227692  \n",
       "12   0.413243  0.137607  0.806306  0.206463  \n",
       "13   0.511384  0.178849  0.843702  0.265013  \n",
       "14   0.496697  0.153532  0.840899  0.234560  \n",
       "15   0.484064  0.148836  0.832006  0.227670  \n",
       "16   0.501637  0.156390  0.839108  0.238444  \n",
       "17   0.418829  0.141690  0.813645  0.211747  \n",
       "18   0.518409  0.178236  0.844814  0.265269  \n",
       "19   0.501644  0.155778  0.844305  0.237732  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{path}training_runs/train_{model.name}.csv')\n",
    "train_df['f1_score'] = 2 * (train_df['precision'] * train_df['recall']) / (train_df['precision'] + train_df['recall'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.082616</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.546376</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.787540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043363</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.611621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.557857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679413</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.042842</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.617911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.041662</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.614317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.050255</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.558207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.045580</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.618510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.078402</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.042645</td>\n",
       "      <td>0.989683</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61005.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.690046</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.037159</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.727236</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.037501</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.727985</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.038603</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61201.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.776308</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.728734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.498802</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.725739</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.041917</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.675319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy    TP       TN     FP     FN  precision   \n",
       "0       0  0.082616         0.993651   0.0  61348.0    0.0  392.0   0.000000  \\\n",
       "1       1  0.037789         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "2       2  0.043363         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "3       3  0.050441         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "4       4  0.041777         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "5       5  0.042842         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "6       6  0.041662         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "7       7  0.050255         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "8       8  0.045580         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "9       9  0.078402         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "10     10  0.040415         0.993651  49.0  61299.0   49.0  343.0   0.500000   \n",
       "11     11  0.042645         0.989683  98.0  61005.0  343.0  294.0   0.222222   \n",
       "12     12  0.185606         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "13     13  0.037159         0.993651  49.0  61299.0   49.0  343.0   0.500000   \n",
       "14     14  0.037501         0.993651  49.0  61299.0   49.0  343.0   0.500000   \n",
       "15     15  0.038603         0.992063  49.0  61201.0  147.0  343.0   0.250000   \n",
       "16     16  0.038482         0.992857   0.0  61299.0   49.0  392.0   0.000000   \n",
       "17     17  0.074375         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "18     18  0.037191         0.992857   0.0  61299.0   49.0  392.0   0.000000   \n",
       "19     19  0.041917         0.993651   0.0  61348.0    0.0  392.0   0.000000   \n",
       "\n",
       "    recall       auc  f1_score  \n",
       "0    0.000  0.546376       NaN  \n",
       "1    0.000  0.787540       NaN  \n",
       "2    0.000  0.611621       NaN  \n",
       "3    0.000  0.557857       NaN  \n",
       "4    0.000  0.679413       NaN  \n",
       "5    0.000  0.617911       NaN  \n",
       "6    0.000  0.614317       NaN  \n",
       "7    0.000  0.558207       NaN  \n",
       "8    0.000  0.618510       NaN  \n",
       "9    0.000  0.500000       NaN  \n",
       "10   0.125  0.725240  0.200000  \n",
       "11   0.250  0.690046  0.235294  \n",
       "12   0.000  0.500000       NaN  \n",
       "13   0.125  0.727236  0.200000  \n",
       "14   0.125  0.727985  0.200000  \n",
       "15   0.125  0.776308  0.166667  \n",
       "16   0.000  0.728734       NaN  \n",
       "17   0.000  0.498802       NaN  \n",
       "18   0.000  0.725739       NaN  \n",
       "19   0.000  0.675319       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(f'{path}training_runs/validation_{model.name}.csv')\n",
    "val_df['f1_score'] = 2 * (val_df['precision'] * val_df['recall']) / (val_df['precision'] + val_df['recall'])\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epoch with the best performance on validation is **14**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
