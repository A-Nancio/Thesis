{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from machine_learning.models import FeedzaiConcatProduction\n",
    "from data_processing.batch_generator import load_test_set\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedzaiConcatProduction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.5121839e-23]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transaction = np.load(f'{path}data/test/all_transactions.npy')[0]\n",
    "test_labels = np.load(f'{path}data/test/all_labels.npy').astype(float)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.load(f'{path}data/test/all_transactions.npy'), \n",
    "     test_labels)\n",
    ").batch(1)\n",
    "# initialize weights\n",
    "model(np.expand_dims(sample_transaction, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>59.0</td>\n",
       "      <td>999678.0</td>\n",
       "      <td>14540.0</td>\n",
       "      <td>4839.0</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.513576</td>\n",
       "      <td>0.006052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.035892</td>\n",
       "      <td>0.995060</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1014062.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.619871</td>\n",
       "      <td>0.007883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.995214</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1014185.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4845.0</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.808517</td>\n",
       "      <td>0.021268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.022022</td>\n",
       "      <td>0.995267</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1014136.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>0.656904</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.061125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.020792</td>\n",
       "      <td>0.995345</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1014067.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4593.0</td>\n",
       "      <td>0.668860</td>\n",
       "      <td>0.062270</td>\n",
       "      <td>0.853154</td>\n",
       "      <td>0.113934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1013972.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>4484.0</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.084524</td>\n",
       "      <td>0.855154</td>\n",
       "      <td>0.148974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.995417</td>\n",
       "      <td>552.0</td>\n",
       "      <td>1013893.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>0.629418</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.856324</td>\n",
       "      <td>0.191169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.995443</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1013831.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>0.623541</td>\n",
       "      <td>0.130870</td>\n",
       "      <td>0.857391</td>\n",
       "      <td>0.216335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.995517</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1013749.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.162924</td>\n",
       "      <td>0.860843</td>\n",
       "      <td>0.258881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.995659</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1013681.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>3887.0</td>\n",
       "      <td>0.653101</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.313683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.018091</td>\n",
       "      <td>0.995589</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1013610.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>3887.0</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.872168</td>\n",
       "      <td>0.310265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.016656</td>\n",
       "      <td>0.996006</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1013461.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>0.676772</td>\n",
       "      <td>0.323601</td>\n",
       "      <td>0.884989</td>\n",
       "      <td>0.437845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.015879</td>\n",
       "      <td>0.996228</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>1013518.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3144.0</td>\n",
       "      <td>0.714751</td>\n",
       "      <td>0.358105</td>\n",
       "      <td>0.895358</td>\n",
       "      <td>0.477149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>1013484.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>0.730246</td>\n",
       "      <td>0.405676</td>\n",
       "      <td>0.892643</td>\n",
       "      <td>0.521591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1013439.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>2913.0</td>\n",
       "      <td>0.718162</td>\n",
       "      <td>0.405267</td>\n",
       "      <td>0.893716</td>\n",
       "      <td>0.518141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.996651</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>1013521.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>0.757902</td>\n",
       "      <td>0.445488</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.561142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1013577.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>2953.0</td>\n",
       "      <td>0.752127</td>\n",
       "      <td>0.397101</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>0.519776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>1013493.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>0.721368</td>\n",
       "      <td>0.383218</td>\n",
       "      <td>0.901265</td>\n",
       "      <td>0.500533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.996604</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>1013544.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>0.757989</td>\n",
       "      <td>0.430992</td>\n",
       "      <td>0.904151</td>\n",
       "      <td>0.549525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.996506</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>1013517.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.744067</td>\n",
       "      <td>0.416088</td>\n",
       "      <td>0.897543</td>\n",
       "      <td>0.533717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy      TP         TN       FP      FN   \n",
       "0       0  0.293435         0.980985    59.0   999678.0  14540.0  4839.0  \\\n",
       "1       1  0.035892         0.995060    20.0  1014062.0    156.0  4878.0   \n",
       "2       2  0.024394         0.995214    53.0  1014185.0     33.0  4845.0   \n",
       "3       3  0.022022         0.995267   157.0  1014136.0     82.0  4741.0   \n",
       "4       4  0.020792         0.995345   305.0  1014067.0    151.0  4593.0   \n",
       "5       5  0.020330         0.995359   414.0  1013972.0    246.0  4484.0   \n",
       "6       6  0.019816         0.995417   552.0  1013893.0    325.0  4346.0   \n",
       "7       7  0.019586         0.995443   641.0  1013831.0    387.0  4257.0   \n",
       "8       8  0.019170         0.995517   798.0  1013749.0    469.0  4100.0   \n",
       "9       9  0.018486         0.995659  1011.0  1013681.0    537.0  3887.0   \n",
       "10     10  0.018091         0.995589  1011.0  1013610.0    608.0  3887.0   \n",
       "11     11  0.016656         0.996006  1585.0  1013461.0    757.0  3313.0   \n",
       "12     12  0.015879         0.996228  1754.0  1013518.0    700.0  3144.0   \n",
       "13     13  0.015435         0.996423  1987.0  1013484.0    734.0  2911.0   \n",
       "14     14  0.015372         0.996377  1985.0  1013439.0    779.0  2913.0   \n",
       "15     15  0.014347         0.996651  2182.0  1013521.0    697.0  2716.0   \n",
       "16     16  0.014707         0.996473  1945.0  1013577.0    641.0  2953.0   \n",
       "17     17  0.014983         0.996324  1877.0  1013493.0    725.0  3021.0   \n",
       "18     18  0.014315         0.996604  2111.0  1013544.0    674.0  2787.0   \n",
       "19     19  0.014777         0.996506  2038.0  1013517.0    701.0  2860.0   \n",
       "\n",
       "    precision    recall       auc  f1_score  \n",
       "0    0.004041  0.012046  0.513576  0.006052  \n",
       "1    0.113636  0.004083  0.619871  0.007883  \n",
       "2    0.616279  0.010821  0.808517  0.021268  \n",
       "3    0.656904  0.032054  0.843077  0.061125  \n",
       "4    0.668860  0.062270  0.853154  0.113934  \n",
       "5    0.627273  0.084524  0.855154  0.148974  \n",
       "6    0.629418  0.112699  0.856324  0.191169  \n",
       "7    0.623541  0.130870  0.857391  0.216335  \n",
       "8    0.629834  0.162924  0.860843  0.258881  \n",
       "9    0.653101  0.206411  0.864894  0.313683  \n",
       "10   0.624460  0.206411  0.872168  0.310265  \n",
       "11   0.676772  0.323601  0.884989  0.437845  \n",
       "12   0.714751  0.358105  0.895358  0.477149  \n",
       "13   0.730246  0.405676  0.892643  0.521591  \n",
       "14   0.718162  0.405267  0.893716  0.518141  \n",
       "15   0.757902  0.445488  0.903000  0.561142  \n",
       "16   0.752127  0.397101  0.902222  0.519776  \n",
       "17   0.721368  0.383218  0.901265  0.500533  \n",
       "18   0.757989  0.430992  0.904151  0.549525  \n",
       "19   0.744067  0.416088  0.897543  0.533717  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{path}training_runs/train_{model.name}.csv')\n",
    "train_df['f1_score'] = 2 * (train_df['precision'] * train_df['recall']) / (train_df['precision'] + train_df['recall'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.525060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.805212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.826178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.799021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030842</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.824780</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833866</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.031402</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.841104</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.840555</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.031321</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.843850</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.030883</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.845298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.784545</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.032687</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.845797</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.034902</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.795777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.681759</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.858277</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.680561</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.855082</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.031135</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61299.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.782248</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy    TP       TN    FP     FN  precision   \n",
       "0       0  0.049498         0.993651   0.0  61348.0   0.0  392.0   0.000000  \\\n",
       "1       1  0.033804         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "2       2  0.030755         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "3       3  0.031669         0.992857   0.0  61299.0  49.0  392.0   0.000000   \n",
       "4       4  0.030842         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "5       5  0.029460         0.993651  49.0  61299.0  49.0  343.0   0.500000   \n",
       "6       6  0.031402         0.993651  49.0  61299.0  49.0  343.0   0.500000   \n",
       "7       7  0.030957         0.992857  49.0  61250.0  98.0  343.0   0.333333   \n",
       "8       8  0.031321         0.993651  49.0  61299.0  49.0  343.0   0.500000   \n",
       "9       9  0.030883         0.992857   0.0  61299.0  49.0  392.0   0.000000   \n",
       "10     10  0.032747         0.992857   0.0  61299.0  49.0  392.0   0.000000   \n",
       "11     11  0.032687         0.992857   0.0  61299.0  49.0  392.0   0.000000   \n",
       "12     12  0.033655         0.992857  49.0  61250.0  98.0  343.0   0.333333   \n",
       "13     13  0.034902         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "14     14  0.038125         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "15     15  0.027045         0.993651  98.0  61250.0  98.0  294.0   0.500000   \n",
       "16     16  0.030271         0.993651   0.0  61348.0   0.0  392.0   0.000000   \n",
       "17     17  0.034704         0.994444  49.0  61348.0   0.0  343.0   1.000000   \n",
       "18     18  0.030655         0.993651  49.0  61299.0  49.0  343.0   0.500000   \n",
       "19     19  0.031135         0.993651  49.0  61299.0  49.0  343.0   0.500000   \n",
       "\n",
       "    recall       auc  f1_score  \n",
       "0    0.000  0.525060       NaN  \n",
       "1    0.000  0.805212       NaN  \n",
       "2    0.000  0.826178       NaN  \n",
       "3    0.000  0.799021       NaN  \n",
       "4    0.000  0.824780       NaN  \n",
       "5    0.125  0.833866  0.200000  \n",
       "6    0.125  0.841104  0.200000  \n",
       "7    0.125  0.840555  0.181818  \n",
       "8    0.125  0.843850  0.200000  \n",
       "9    0.000  0.845298       NaN  \n",
       "10   0.000  0.784545       NaN  \n",
       "11   0.000  0.781550       NaN  \n",
       "12   0.125  0.845797  0.181818  \n",
       "13   0.000  0.795777       NaN  \n",
       "14   0.000  0.681759       NaN  \n",
       "15   0.250  0.858277  0.333333  \n",
       "16   0.000  0.797973       NaN  \n",
       "17   0.125  0.680561  0.222222  \n",
       "18   0.125  0.855082  0.200000  \n",
       "19   0.125  0.782248  0.200000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(f'{path}training_runs/validation_{model.name}.csv')\n",
    "val_df['f1_score'] = 2 * (val_df['precision'] * val_df['recall']) / (val_df['precision'] + val_df['recall'])\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epoch with the best performance on validation is **15**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
