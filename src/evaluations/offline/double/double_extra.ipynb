{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dense, Dropout, GRU\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from machine_learning.models import DoubleExtraProduction\n",
    "from data_processing.batch_generator import load_test_set\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DoubleExtraProduction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.FalseNegatives(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.34220168]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transaction = np.load(f'{path}data/test/all_transactions.npy')[0]\n",
    "test_labels = np.load(f'{path}data/test/all_labels.npy').astype(float)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.load(f'{path}data/test/all_transactions.npy'), \n",
    "     test_labels)\n",
    ").batch(1)\n",
    "# initialize weights\n",
    "model(np.expand_dims(sample_transaction, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>0.989794</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1008708.0</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>4891.0</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.609014</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028937</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>0.995251</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1014122.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4744.0</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.785897</td>\n",
       "      <td>0.059829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.995422</td>\n",
       "      <td>621.0</td>\n",
       "      <td>1013829.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>0.614851</td>\n",
       "      <td>0.126786</td>\n",
       "      <td>0.837810</td>\n",
       "      <td>0.210223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.019337</td>\n",
       "      <td>0.995545</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1013736.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>4058.0</td>\n",
       "      <td>0.635401</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.841572</td>\n",
       "      <td>0.270096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.995679</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1013717.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>0.665107</td>\n",
       "      <td>0.203144</td>\n",
       "      <td>0.840006</td>\n",
       "      <td>0.311229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1013713.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>3838.0</td>\n",
       "      <td>0.677316</td>\n",
       "      <td>0.216415</td>\n",
       "      <td>0.849702</td>\n",
       "      <td>0.328021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1013619.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>0.678993</td>\n",
       "      <td>0.258677</td>\n",
       "      <td>0.846778</td>\n",
       "      <td>0.374630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.995954</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>1013654.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>3559.0</td>\n",
       "      <td>0.703626</td>\n",
       "      <td>0.273377</td>\n",
       "      <td>0.846147</td>\n",
       "      <td>0.393766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>0.995924</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1013690.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.259698</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>0.379815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.017475</td>\n",
       "      <td>0.995899</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1013556.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3517.0</td>\n",
       "      <td>0.675967</td>\n",
       "      <td>0.281952</td>\n",
       "      <td>0.851513</td>\n",
       "      <td>0.397925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.017253</td>\n",
       "      <td>0.996017</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>1013661.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>0.714798</td>\n",
       "      <td>0.285014</td>\n",
       "      <td>0.852708</td>\n",
       "      <td>0.407532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.996017</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>1013579.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>0.698158</td>\n",
       "      <td>0.301756</td>\n",
       "      <td>0.851611</td>\n",
       "      <td>0.421383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.995927</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1013614.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>3547.0</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.275827</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>0.394280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1013613.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>0.712589</td>\n",
       "      <td>0.306247</td>\n",
       "      <td>0.852464</td>\n",
       "      <td>0.428388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.016718</td>\n",
       "      <td>0.996187</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1013617.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.728546</td>\n",
       "      <td>0.329318</td>\n",
       "      <td>0.854824</td>\n",
       "      <td>0.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>1013592.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>0.715455</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>0.858657</td>\n",
       "      <td>0.443505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>1013601.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>3324.0</td>\n",
       "      <td>0.718393</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>0.861867</td>\n",
       "      <td>0.444068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy      TP         TN      FP      FN   \n",
       "0       0  0.039974         0.989794     7.0  1008708.0  5510.0  4891.0  \\\n",
       "1       1  0.028937         0.995194     0.0  1014218.0     0.0  4898.0   \n",
       "2       2  0.028565         0.995194     0.0  1014218.0     0.0  4898.0   \n",
       "3       3  0.027725         0.995194     0.0  1014218.0     0.0  4898.0   \n",
       "4       4  0.024397         0.995251   154.0  1014122.0    96.0  4744.0   \n",
       "5       5  0.020300         0.995422   621.0  1013829.0   389.0  4277.0   \n",
       "6       6  0.019337         0.995545   840.0  1013736.0   482.0  4058.0   \n",
       "7       7  0.018967         0.995679   995.0  1013717.0   501.0  3903.0   \n",
       "8       8  0.018385         0.995738  1060.0  1013713.0   505.0  3838.0   \n",
       "9       9  0.017909         0.995849  1267.0  1013619.0   599.0  3631.0   \n",
       "10     10  0.017724         0.995954  1339.0  1013654.0   564.0  3559.0   \n",
       "11     11  0.017678         0.995924  1272.0  1013690.0   528.0  3626.0   \n",
       "12     12  0.017475         0.995899  1381.0  1013556.0   662.0  3517.0   \n",
       "13     13  0.017253         0.996017  1396.0  1013661.0   557.0  3502.0   \n",
       "14     14  0.017108         0.996017  1478.0  1013579.0   639.0  3420.0   \n",
       "15     15  0.017117         0.995927  1351.0  1013614.0   604.0  3547.0   \n",
       "16     16  0.016904         0.996072  1500.0  1013613.0   605.0  3398.0   \n",
       "17     17  0.016718         0.996187  1613.0  1013617.0   601.0  3285.0   \n",
       "18     18  0.016743         0.996124  1574.0  1013592.0   626.0  3324.0   \n",
       "19     19  0.016627         0.996133  1574.0  1013601.0   617.0  3324.0   \n",
       "\n",
       "    precision    recall       auc  f1_score  \n",
       "0    0.001269  0.001429  0.609014  0.001344  \n",
       "1    0.000000  0.000000  0.671946       NaN  \n",
       "2    0.000000  0.000000  0.693680       NaN  \n",
       "3    0.000000  0.000000  0.714141       NaN  \n",
       "4    0.616000  0.031441  0.785897  0.059829  \n",
       "5    0.614851  0.126786  0.837810  0.210223  \n",
       "6    0.635401  0.171499  0.841572  0.270096  \n",
       "7    0.665107  0.203144  0.840006  0.311229  \n",
       "8    0.677316  0.216415  0.849702  0.328021  \n",
       "9    0.678993  0.258677  0.846778  0.374630  \n",
       "10   0.703626  0.273377  0.846147  0.393766  \n",
       "11   0.706667  0.259698  0.846726  0.379815  \n",
       "12   0.675967  0.281952  0.851513  0.397925  \n",
       "13   0.714798  0.285014  0.852708  0.407532  \n",
       "14   0.698158  0.301756  0.851611  0.421383  \n",
       "15   0.691049  0.275827  0.853081  0.394280  \n",
       "16   0.712589  0.306247  0.852464  0.428388  \n",
       "17   0.728546  0.329318  0.854824  0.453600  \n",
       "18   0.715455  0.321356  0.858657  0.443505  \n",
       "19   0.718393  0.321356  0.861867  0.444068  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{path}training_runs/train_{model.name}.csv')\n",
    "train_df['f1_score'] = 2 * (train_df['precision'] * train_df['recall']) / (train_df['precision'] + train_df['recall'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696482</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042922</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.042368</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.041346</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.038091</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.040896</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797437</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.045527</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61005.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.690511</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.990266</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61090.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.159609</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.734591</td>\n",
       "      <td>0.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>98.0</td>\n",
       "      <td>60858.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>0.987253</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60904.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.801960</td>\n",
       "      <td>0.110734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.036790</td>\n",
       "      <td>0.987885</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60943.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.107930</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.749748</td>\n",
       "      <td>0.115839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.039384</td>\n",
       "      <td>0.987253</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60904.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.711527</td>\n",
       "      <td>0.110734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.039635</td>\n",
       "      <td>0.985698</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60808.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.750579</td>\n",
       "      <td>0.099898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>0.985617</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60803.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.082492</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.829692</td>\n",
       "      <td>0.099391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60907.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.773975</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60662.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.800558</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.040538</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>190.0</td>\n",
       "      <td>60515.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>0.484694</td>\n",
       "      <td>0.777313</td>\n",
       "      <td>0.268551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.049462</td>\n",
       "      <td>0.982102</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60564.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.083041</td>\n",
       "      <td>0.181122</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.113873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.046647</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60665.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.168088</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.679692</td>\n",
       "      <td>0.227535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.035235</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>49.0</td>\n",
       "      <td>61201.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  binary_accuracy     TP       TN     FP     FN  precision   \n",
       "0       0  0.042690         0.993651    0.0  61348.0    0.0  392.0   0.000000  \\\n",
       "1       1  0.042922         0.993651    0.0  61348.0    0.0  392.0   0.000000   \n",
       "2       2  0.042368         0.993651    0.0  61348.0    0.0  392.0   0.000000   \n",
       "3       3  0.041346         0.993651    0.0  61348.0    0.0  392.0   0.000000   \n",
       "4       4  0.038091         0.992063    0.0  61250.0   98.0  392.0   0.000000   \n",
       "5       5  0.040896         0.992063    0.0  61250.0   98.0  392.0   0.000000   \n",
       "6       6  0.045527         0.988889   49.0  61005.0  343.0  343.0   0.125000   \n",
       "7       7  0.037200         0.990266   49.0  61090.0  258.0  343.0   0.159609   \n",
       "8       8  0.041582         0.987302   98.0  60858.0  490.0  294.0   0.166667   \n",
       "9       9  0.039920         0.987253   49.0  60904.0  444.0  343.0   0.099391   \n",
       "10     10  0.036790         0.987885   49.0  60943.0  405.0  343.0   0.107930   \n",
       "11     11  0.039384         0.987253   49.0  60904.0  444.0  343.0   0.099391   \n",
       "12     12  0.039635         0.985698   49.0  60808.0  540.0  343.0   0.083192   \n",
       "13     13  0.041648         0.985617   49.0  60803.0  545.0  343.0   0.082492   \n",
       "14     14  0.042311         0.987302   49.0  60907.0  441.0  343.0   0.100000   \n",
       "15     15  0.041714         0.983333   49.0  60662.0  686.0  343.0   0.066667   \n",
       "16     16  0.040538         0.983236  190.0  60515.0  833.0  202.0   0.185728   \n",
       "17     17  0.049462         0.982102   71.0  60564.0  784.0  321.0   0.083041   \n",
       "18     18  0.046647         0.984823  138.0  60665.0  683.0  254.0   0.168088   \n",
       "19     19  0.035235         0.992063   49.0  61201.0  147.0  343.0   0.250000   \n",
       "\n",
       "      recall       auc  f1_score  \n",
       "0   0.000000  0.696482       NaN  \n",
       "1   0.000000  0.699126       NaN  \n",
       "2   0.000000  0.696999       NaN  \n",
       "3   0.000000  0.733947       NaN  \n",
       "4   0.000000  0.804266       NaN  \n",
       "5   0.000000  0.797437       NaN  \n",
       "6   0.125000  0.690511  0.125000  \n",
       "7   0.125000  0.734591  0.140200  \n",
       "8   0.250000  0.697939  0.200000  \n",
       "9   0.125000  0.801960  0.110734  \n",
       "10  0.125000  0.749748  0.115839  \n",
       "11  0.125000  0.711527  0.110734  \n",
       "12  0.125000  0.750579  0.099898  \n",
       "13  0.125000  0.829692  0.099391  \n",
       "14  0.125000  0.773975  0.111111  \n",
       "15  0.125000  0.800558  0.086957  \n",
       "16  0.484694  0.777313  0.268551  \n",
       "17  0.181122  0.723553  0.113873  \n",
       "18  0.352041  0.679692  0.227535  \n",
       "19  0.125000  0.671353  0.166667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(f'{path}training_runs/validation_{model.name}.csv')\n",
    "val_df['f1_score'] = 2 * (val_df['precision'] * val_df['recall']) / (val_df['precision'] + val_df['recall'])\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epoch with the best performance on validation is **16**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
